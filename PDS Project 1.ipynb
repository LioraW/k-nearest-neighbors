{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5556362",
   "metadata": {},
   "source": [
    "<h2> Liora Wachsstock <h2/>\n",
    "<h3> Python For Data Science Project 1 <h3/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef8201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2c520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(X_train, X_test, y_train, y_test, result, seed):\n",
    "    print(\"The seed was\", seed)\n",
    "    \n",
    "    print(\"Training Data:\")\n",
    "    for i, point in enumerate(X_train):\n",
    "        print(point, \"    \", y_train[i])\n",
    "    \n",
    "    print(\"\\nTest Data:\")\n",
    "    for i, point in enumerate(X_test):\n",
    "        print(point, \"    \", y_test[i])\n",
    "    \n",
    "    \n",
    "    print(\"\\nPredicted labels:\")\n",
    "    for i, point in enumerate(X_test):\n",
    "        print(point, \"    \", result[i])\n",
    "    \n",
    "    print(\"Accuracy: \", round((np.sum(result == y_test)/len(result))*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefc2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(seed_num, TOTAL_SAMPLE_SIZE,n,d,m,s):\n",
    "    label_names = [\"good\", \"bad\", \"ugly\"]\n",
    "    \n",
    "    #Seed\n",
    "    rng = np.random.default_rng(seed = seed_num)\n",
    "    \n",
    "    #Generate Data set and labels\n",
    "    total_sample_set = rng.normal(m, s, d*TOTAL_SAMPLE_SIZE).reshape(TOTAL_SAMPLE_SIZE, d)\n",
    "    labels = rng.choice(label_names, TOTAL_SAMPLE_SIZE)\n",
    "    \n",
    "    #Get the indicies for separating test and training data\n",
    "    training_ind = np.random.choice(np.arange(TOTAL_SAMPLE_SIZE), n, replace=False) #get random indicies for training data\n",
    "    test_ind = np.setdiff1d(np.arange(TOTAL_SAMPLE_SIZE), training_ind) #get the indicies not chosen\n",
    "    \n",
    "    #Separate the data\n",
    "    X_train = total_sample_set[training_ind]\n",
    "    y_train = labels[training_ind]\n",
    "    \n",
    "    X_test = total_sample_set[test_ind]\n",
    "    y_test = labels[test_ind]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72e2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh(distance):\n",
    "    return 1/(distance + 0.0001)\n",
    "\n",
    "def distances(train, point):\n",
    "    return np.linalg.norm((train - point), axis=1)\n",
    "\n",
    "def vote(distances, kclasses, k):\n",
    "    labels = [\"good\", \"bad\", \"ugly\"]\n",
    "    \n",
    "    votes = np.zeros(len(labels), dtype=np.float32)\n",
    "    \n",
    "    weight = np.vectorize(weigh)\n",
    "    \n",
    "    w = weight(distances)\n",
    "    \n",
    "    votes = [np.sum(w[kclasses == labels[0]]), np.sum(w[kclasses == labels[1]]), np.sum(w[kclasses == labels[2]])]\n",
    "    return labels[np.argmax(votes)] #get the winner\n",
    "\n",
    "def kneighbors(X_train, y_train, X_test, k):\n",
    "    classes = []\n",
    "    for point in X_test:\n",
    "        dists = distances(X_train, point)      #1.Find its Euclidean distance from each of the n points in the training data set \n",
    "        smallestK = np.argsort(dists)[:k]    #2.Pick the nearest K points (returns the indicies)\n",
    "        classes.append(vote(dists[smallestK], y_train[smallestK], k)) #3.Output the class by weighted voting using the K nearest neighbors in the above step \n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260cbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SAMPLE_SIZE = 10 # Total number of samples (data points or vectors) in the training set plus test set\n",
    "n = 7 #Number of samples (data points or vectors) in the training set\n",
    "d = 3 #Number of features\n",
    "K = 3 #Stipulated number of nearest neighbors\n",
    "m = 5 #mean of normal distribution\n",
    "s = 2 #std of normal distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6873df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run #1\n",
      "The seed was 42\n",
      "Training Data:\n",
      "[3.63814091 7.44508268 4.69094104]      bad\n",
      "[3.28141507 5.73750157 3.0822348 ]      good\n",
      "[6.88112943 1.09792962 2.39564099]      ugly\n",
      "[5.60943416 2.92003179 6.50090239]      ugly\n",
      "[6.7569006  4.90014818 4.63027527]      ugly\n",
      "[5.25568081 4.36751482 4.96639768]      bad\n",
      "[5.1320614  7.25448241 5.93501868]      bad\n",
      "\n",
      "Test Data:\n",
      "[3.29391214 6.75879595 6.55558387]      ugly\n",
      "[4.14334436 4.2957329  6.06461837]      good\n",
      "[5.73088813 5.82546522 5.86164201]      bad\n",
      "\n",
      "Predicted labels:\n",
      "[3.29391214 6.75879595 6.55558387]      bad\n",
      "[4.14334436 4.2957329  6.06461837]      ugly\n",
      "[5.73088813 5.82546522 5.86164201]      bad\n",
      "Accuracy:  33.33 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Run #1\")\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = generate_data(seed, TOTAL_SAMPLE_SIZE, n, d, m, s)\n",
    "\n",
    "result = kneighbors(X_train, y_train, X_test, K)\n",
    "print_data(X_train, X_test, y_train, y_test, result, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bb5d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run #2\n",
      "The seed was 15\n",
      "Training Data:\n",
      "[1.8789206  5.40957495 6.38195717]      good\n",
      "[7.88661118 3.77339661 5.1555479 ]      ugly\n",
      "[3.3740433  4.15533326 0.4411023 ]      good\n",
      "[2.13825395 3.12690457 5.78787671]      ugly\n",
      "[7.78652099 6.06568803 8.32127508]      good\n",
      "[2.11293722 7.03412758 3.8087027 ]      bad\n",
      "[9.18816997 6.45737788 3.92202114]      good\n",
      "\n",
      "Test Data:\n",
      "[3.95182674 6.05123241 6.61464725]      bad\n",
      "[5.40297558 5.42995584 5.65903622]      good\n",
      "[6.26844023 4.64451783 1.95118423]      good\n",
      "\n",
      "Predicted labels:\n",
      "[3.95182674 6.05123241 6.61464725]      good\n",
      "[5.40297558 5.42995584 5.65903622]      good\n",
      "[6.26844023 4.64451783 1.95118423]      good\n",
      "Accuracy:  66.67 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Run #2\")\n",
    "seed = 15\n",
    "X_train, X_test, y_train, y_test = generate_data(seed, TOTAL_SAMPLE_SIZE, n, d, m, s)\n",
    "\n",
    "result = kneighbors(X_train, y_train, X_test, K)\n",
    "\n",
    "print_data(X_train, X_test, y_train, y_test, result, seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
