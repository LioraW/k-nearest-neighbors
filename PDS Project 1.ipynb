{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef8201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import starements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2c520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(X_train, X_test, y_train, y_test):\n",
    "    print(\"Training Data:\")\n",
    "    for i, point in enumerate(X_train):\n",
    "        print(point, \"    \", y_train[i])\n",
    "    print(\"\\nTest Data:\")\n",
    "    for i, point in enumerate(X_test):\n",
    "        print(point, \"    \", y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefc2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(TOTAL_SAMPLE_SIZE,n,d,m,s):\n",
    "    label_names = [\"good\", \"bad\", \"ugly\"]\n",
    "    #Seed\n",
    "    rng = np.random.default_rng(seed = 42)\n",
    "    \n",
    "    #Generate Data set and labels\n",
    "    total_sample_set = rng.normal(m, s, d*TOTAL_SAMPLE_SIZE).reshape(TOTAL_SAMPLE_SIZE, d)\n",
    "    labels = rng.choice(label_names, TOTAL_SAMPLE_SIZE)\n",
    "    \n",
    "    #Get the indicies for separating test and training data\n",
    "    training_ind = np.random.choice(np.arange(TOTAL_SAMPLE_SIZE), n, replace=False) #get random indicies for training data\n",
    "    test_ind = np.setdiff1d(np.arange(TOTAL_SAMPLE_SIZE), training_ind) #get the indicies not chosen\n",
    "    \n",
    "    #Separate the data\n",
    "    X_train = total_sample_set[training_ind]\n",
    "    y_train = labels[training_ind]\n",
    "    \n",
    "    X_test = total_sample_set[test_ind]\n",
    "    y_test = labels[test_ind]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72e2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh(distance):\n",
    "    return 1/(distance + 0.0001)\n",
    "\n",
    "def distances(train, point):\n",
    "    return np.linalg.norm((train - point), axis=1)\n",
    "\n",
    "def vote(distances, kclasses, k):\n",
    "    labels = [\"good\", \"bad\", \"ugly\"]\n",
    "    \n",
    "    votes = np.zeros(len(labels), dtype=np.float32)\n",
    "    \n",
    "    weight = np.vectorize(weigh)\n",
    "    \n",
    "    w = weight(distances)\n",
    "    \n",
    "    votes = [np.sum(w[kclasses == labels[0]]), np.sum(w[kclasses == labels[1]]), np.sum(w[kclasses == labels[2]])]\n",
    "    \n",
    "    return labels[np.argmax(votes)] #get the winner\n",
    "\n",
    "def kneighbors(X_train, y_train, X_test, k):\n",
    "    classes = []\n",
    "    for point in X_test:\n",
    "        dists = distances(X_train, point)      #1.Find its Euclidean distance from each of the n points in the training data set \n",
    "        smallestK = np.argsort(dists)[:k]    #2.Pick the nearest K points (returns the indicies)\n",
    "        classes.append(vote(dists[smallestK], y_train[smallestK], k)) #3.Output the class by weighted voting using the K nearest neighbors in the above step \n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260cbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SAMPLE_SIZE = 50 # Total number of samples (data points or vectors) in the training set plus test set\n",
    "n = 45 #Number of samples (data points or vectors) in the training set\n",
    "d = 3 #Number of features\n",
    "K = 9 #Stipulated number of nearest neighbors\n",
    "m = 5 #mean of normal distribution\n",
    "s = 2 #std of normal distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6873df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "[1.63426046 4.33022994 5.32550613]      ugly\n",
      "[6.17244466 6.42245316 6.58669447]      good\n",
      "[5.02498824 5.96149332 5.89306235]      ugly\n",
      "[4.58912488 3.09995589 4.32193385]      ugly\n",
      "[3.29391214 6.75879595 6.55558387]      bad\n",
      "[4.28747206 6.47503114 3.13276464]      good\n",
      "[5.1320614  7.25448241 5.93501868]      good\n",
      "[4.30254986 4.07529641 6.71595176]      good\n",
      "[2.95300501 5.35855127 5.43999337]      ugly\n",
      "[4.84056358 1.62533113 2.10577506]      ugly\n",
      "[6.38097071 4.14549471 5.31707938]      bad\n",
      "[6.35782713 5.13515814 5.5782388 ]      good\n",
      "[5.60943416 2.92003179 6.50090239]      bad\n",
      "[4.61739135 2.44862735 2.73342557]      good\n",
      "[4.05925469 3.7222443  4.4497155 ]      bad\n",
      "[7.92660578 2.62247389 3.72049693]      ugly\n",
      "[9.2832952  4.18716997 3.97551454]      good\n",
      "[6.26257645 2.08568836 4.36065757]      good\n",
      "[6.68061627 1.54535915 5.86884729]      bad\n",
      "[7.71837515 6.67022249 5.71374212]      good\n",
      "[6.25118079 4.38130692 5.91355048]      bad\n",
      "[3.37411781 4.16928548 3.7758064 ]      good\n",
      "[5.04370429 8.20355778 4.52128875]      bad\n",
      "[2.96884184 5.62702769 6.67625314]      good\n",
      "[3.63814091 7.44508268 4.69094104]      ugly\n",
      "[5.25568081 4.36751482 4.96639768]      good\n",
      "[4.14334436 4.2957329  6.06461837]      good\n",
      "[5.4754712  3.81170009 2.10788429]      good\n",
      "[3.67614812 4.27389231 4.23652421]      bad\n",
      "[4.71841823 7.13196046 5.31409713]      bad\n",
      "[6.30118558 6.48650834 6.08630854]      ugly\n",
      "[5.14425902 3.94101458 5.46535242]      bad\n",
      "[4.77210508 3.31968705 3.35103757]      ugly\n",
      "[6.7569006  4.90014818 4.63027527]      bad\n",
      "[6.88112943 1.09792962 2.39564099]      good\n",
      "[3.18904189 4.24367489 7.5984566 ]      good\n",
      "[3.16109543 5.99432149 5.28485147]      good\n",
      "[5.73088813 5.82546522 5.86164201]      good\n",
      "[6.27030189 4.55555461 2.05838741]      good\n",
      "[3.14684812 4.22038039 2.2466277 ]      ugly\n",
      "[5.43737719 6.74285756 5.4471911 ]      ugly\n",
      "[ 8.99346178 10.82772493  5.82881887]      bad\n",
      "[3.66898059 5.46432265 5.23337162]      ugly\n",
      "[2.35460078 3.00550634 5.79954845]      ugly\n",
      "[2.60832071 5.97394496 4.06119532]      good\n",
      "\n",
      "Test Data:\n",
      "[3.28141507 5.73750157 3.0822348 ]      good\n",
      "[3.37245454 6.23195885 7.25794459]      bad\n",
      "[7.98988262 3.26833777 6.93655671]      ugly\n",
      "[6.33077022 4.80302903 4.15340338]      bad\n",
      "[3.02092376 0.73590744 5.53542292]      good\n",
      "['good', 'good', 'bad', 'bad', 'good']\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "# Run 1\n",
    "X_train, X_test, y_train, y_test = generate_data(TOTAL_SAMPLE_SIZE, n, d, m, s)\n",
    "print_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "result = kneighbors(X_train, y_train, X_test, K)\n",
    "print(result)\n",
    "print((np.sum(result == y_test)/len(result))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bb5d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "[5.73088813 5.82546522 5.86164201]      good\n",
      "[4.77210508 3.31968705 3.35103757]      ugly\n",
      "[3.67614812 4.27389231 4.23652421]      bad\n",
      "[4.30254986 4.07529641 6.71595176]      good\n",
      "[6.30118558 6.48650834 6.08630854]      ugly\n",
      "[3.29391214 6.75879595 6.55558387]      bad\n",
      "[5.25568081 4.36751482 4.96639768]      good\n",
      "[6.17244466 6.42245316 6.58669447]      good\n",
      "[2.95300501 5.35855127 5.43999337]      ugly\n",
      "[ 8.99346178 10.82772493  5.82881887]      bad\n",
      "[5.4754712  3.81170009 2.10788429]      good\n",
      "[6.27030189 4.55555461 2.05838741]      good\n",
      "[3.37245454 6.23195885 7.25794459]      bad\n",
      "[3.37411781 4.16928548 3.7758064 ]      good\n",
      "[3.18904189 4.24367489 7.5984566 ]      good\n",
      "[6.26257645 2.08568836 4.36065757]      good\n",
      "[3.14684812 4.22038039 2.2466277 ]      ugly\n",
      "[5.14425902 3.94101458 5.46535242]      bad\n",
      "[4.61739135 2.44862735 2.73342557]      good\n",
      "[6.33077022 4.80302903 4.15340338]      bad\n",
      "[3.63814091 7.44508268 4.69094104]      ugly\n",
      "[1.63426046 4.33022994 5.32550613]      ugly\n",
      "[3.16109543 5.99432149 5.28485147]      good\n",
      "[2.96884184 5.62702769 6.67625314]      good\n",
      "[5.1320614  7.25448241 5.93501868]      good\n",
      "[4.05925469 3.7222443  4.4497155 ]      bad\n",
      "[9.2832952  4.18716997 3.97551454]      good\n",
      "[4.58912488 3.09995589 4.32193385]      ugly\n",
      "[6.38097071 4.14549471 5.31707938]      bad\n",
      "[4.84056358 1.62533113 2.10577506]      ugly\n",
      "[7.71837515 6.67022249 5.71374212]      good\n",
      "[5.43737719 6.74285756 5.4471911 ]      ugly\n",
      "[3.66898059 5.46432265 5.23337162]      ugly\n",
      "[5.04370429 8.20355778 4.52128875]      bad\n",
      "[5.60943416 2.92003179 6.50090239]      bad\n",
      "[6.68061627 1.54535915 5.86884729]      bad\n",
      "[3.28141507 5.73750157 3.0822348 ]      good\n",
      "[4.71841823 7.13196046 5.31409713]      bad\n",
      "[5.02498824 5.96149332 5.89306235]      ugly\n",
      "[6.25118079 4.38130692 5.91355048]      bad\n",
      "[4.14334436 4.2957329  6.06461837]      good\n",
      "[6.35782713 5.13515814 5.5782388 ]      good\n",
      "[7.98988262 3.26833777 6.93655671]      ugly\n",
      "[2.60832071 5.97394496 4.06119532]      good\n",
      "[4.28747206 6.47503114 3.13276464]      good\n",
      "\n",
      "Test Data:\n",
      "[6.88112943 1.09792962 2.39564099]      good\n",
      "[6.7569006  4.90014818 4.63027527]      bad\n",
      "[2.35460078 3.00550634 5.79954845]      ugly\n",
      "[7.92660578 2.62247389 3.72049693]      ugly\n",
      "[3.02092376 0.73590744 5.53542292]      good\n",
      "['good', 'bad', 'good', 'good', 'good']\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "# Run 2\n",
    "X_train, X_test, y_train, y_test = generate_data(TOTAL_SAMPLE_SIZE, n, d, m, s)\n",
    "print_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "result = kneighbors(X_train, y_train, X_test, K)\n",
    "print(result)\n",
    "print((np.sum(result == y_test)/len(result))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
